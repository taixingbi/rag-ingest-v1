"""
Configuration loaded from environment (.env).
Values are read when Settings() is created so CLI args (dev/qa/prod, local/remote) take effect.
"""

from dataclasses import dataclass, field
import os

from dotenv import load_dotenv

load_dotenv()

# Per-file collection mapping (data/*.json â†’ Chroma collection)
FILE_TO_COLLECTION = {
    "profile.json": "taixing_identity",
    "resume.json": "taixing_resume",
    "qa.json": "taixing_qa",
}


def _env(key: str, default: str) -> str:
    return os.environ.get(key, default)


def _env_int(key: str, default: str) -> int:
    return int(os.environ.get(key, default))


def _env(key: str, default: str) -> str:
    return os.environ.get(key, default)


def _env_int(key: str, default: str) -> int:
    return int(os.environ.get(key, default))


@dataclass
class Settings:
    mongodb_uri: str = field(default_factory=lambda: _env("MONGODB_URI", ""))
    mongodb_db: str = field(default_factory=lambda: _env("MONGODB_DB", "rag"))
    mongodb_collection: str = field(default_factory=lambda: _env("MONGODB_COLLECTION", "rag_chunks"))

    openai_api_key: str = field(default_factory=lambda: _env("OPENAI_API_KEY", ""))
    embed_model: str = field(default_factory=lambda: _env("OPENAI_EMBED_MODEL", "text-embedding-3-small"))

    # Chunking (token-based preferred, char-based fallback)
    chunk_tokens: int = field(default_factory=lambda: _env_int("CHUNK_TOKENS", "1000"))
    overlap_tokens: int = field(default_factory=lambda: _env_int("OVERLAP_TOKENS", "150"))
    chunk_chars: int = field(default_factory=lambda: _env_int("CHUNK_CHARS", "5000"))
    overlap_chars: int = field(default_factory=lambda: _env_int("OVERLAP_CHARS", "800"))

    # Ingest (batch size for embeddings API)
    batch_size: int = field(default_factory=lambda: _env_int("BATCH_SIZE", "64"))
